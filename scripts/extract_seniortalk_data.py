#!/usr/bin/env python3
"""
è§£å‹SeniorTalkæ•°æ®é›†å¹¶æ•´ç†ä¸ºå¯ç”¨çš„æ ¼å¼
"""
import os
import tarfile
import logging
from pathlib import Path
import json
import shutil

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def extract_tar_with_limit(tar_path: str, extract_dir: str, max_files: int = 5):
    """è§£å‹taræ–‡ä»¶ï¼Œé™åˆ¶æ–‡ä»¶æ•°é‡ç”¨äºæµ‹è¯•"""
    
    tar_path = Path(tar_path)
    extract_dir = Path(extract_dir)
    
    logger.info(f"ğŸ“¦ å¼€å§‹è§£å‹: {tar_path.name}")
    logger.info(f"ğŸ“ è§£å‹åˆ°: {extract_dir}")
    logger.info(f"ğŸ”¢ é™åˆ¶æ–‡ä»¶æ•°é‡: {max_files}")
    
    extract_dir.mkdir(parents=True, exist_ok=True)
    
    extracted_files = []
    
    try:
        with tarfile.open(tar_path, 'r') as tar:
            members = tar.getmembers()
            
            # è¿‡æ»¤å‡ºéŸ³é¢‘æ–‡ä»¶
            audio_members = [m for m in members if m.isfile() and m.name.endswith('.wav')]
            
            logger.info(f"ğŸ“Š taråŒ…åŒ…å« {len(audio_members)} ä¸ªwavæ–‡ä»¶")
            
            # åªæå–æŒ‡å®šæ•°é‡çš„æ–‡ä»¶
            selected_members = audio_members[:max_files]
            
            for i, member in enumerate(selected_members):
                logger.info(f"â³ è§£å‹ {i+1}/{len(selected_members)}: {member.name}")
                
                # è§£å‹æ–‡ä»¶
                tar.extract(member, extract_dir)
                
                # è®°å½•æ–‡ä»¶ä¿¡æ¯
                extracted_path = extract_dir / member.name
                if extracted_path.exists():
                    file_size = extracted_path.stat().st_size / (1024 * 1024)  # MB
                    logger.info(f"  âœ… å¤§å°: {file_size:.1f}MB")
                    
                    extracted_files.append({
                        'original_path': member.name,
                        'extracted_path': str(extracted_path),
                        'size_mb': file_size
                    })
                else:
                    logger.warning(f"  âŒ è§£å‹å¤±è´¥: {member.name}")
            
            logger.info(f"ğŸ‰ æˆåŠŸè§£å‹ {len(extracted_files)} ä¸ªæ–‡ä»¶")
            return extracted_files
            
    except Exception as e:
        logger.error(f"âŒ è§£å‹å¤±è´¥: {e}")
        return []

def find_corresponding_transcripts(audio_files: list, base_dir: str):
    """æŸ¥æ‰¾å¯¹åº”çš„è½¬å½•æ–‡ä»¶"""
    
    base_path = Path(base_dir)
    transcripts = {}
    
    logger.info("ğŸ” æŸ¥æ‰¾å¯¹åº”çš„è½¬å½•æ–‡ä»¶...")
    
    # æŸ¥æ‰¾å¯èƒ½çš„è½¬å½•æ–‡ä»¶ç›®å½•
    possible_transcript_dirs = [
        base_path / "sentence_data" / "transcript",
        base_path / "transcript", 
        base_path.parent / "transcript",
        base_path.parent / "sentence_data" / "transcript"
    ]
    
    transcript_files = []
    for transcript_dir in possible_transcript_dirs:
        if transcript_dir.exists():
            transcript_files.extend(list(transcript_dir.glob("*.txt")))
            logger.info(f"ğŸ“ åœ¨ {transcript_dir} æ‰¾åˆ° {len(list(transcript_dir.glob('*.txt')))} ä¸ªtxtæ–‡ä»¶")
    
    # å°è¯•åŒ¹é…éŸ³é¢‘æ–‡ä»¶å’Œè½¬å½•æ–‡ä»¶
    for audio_info in audio_files:
        audio_path = Path(audio_info['extracted_path'])
        audio_stem = audio_path.stem
        
        # å°è¯•æ‰¾åˆ°å¯¹åº”çš„è½¬å½•æ–‡ä»¶
        matching_transcript = None
        for transcript_file in transcript_files:
            if audio_stem in transcript_file.stem or transcript_file.stem in audio_stem:
                matching_transcript = str(transcript_file)
                break
        
        transcripts[audio_stem] = matching_transcript
        
        if matching_transcript:
            logger.info(f"âœ… æ‰¾åˆ°åŒ¹é…: {audio_path.name} -> {Path(matching_transcript).name}")
        else:
            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°è½¬å½•: {audio_path.name}")
    
    return transcripts

def create_dataset_structure(extracted_files: list, transcripts: dict, output_dir: str):
    """åˆ›å»ºæ ‡å‡†çš„æ•°æ®é›†ç»“æ„"""
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    logger.info(f"ğŸ—ï¸ åˆ›å»ºæ•°æ®é›†ç»“æ„: {output_path}")
    
    # åˆ›å»ºæ ‡å‡†ç›®å½•ç»“æ„
    audio_dir = output_path / "audio"
    text_dir = output_path / "text"
    metadata_dir = output_path / "metadata"
    
    for dir_path in [audio_dir, text_dir, metadata_dir]:
        dir_path.mkdir(exist_ok=True)
    
    dataset_items = []
    
    for i, audio_info in enumerate(extracted_files):
        audio_src = Path(audio_info['extracted_path'])
        audio_stem = audio_src.stem
        
        # å¤åˆ¶éŸ³é¢‘æ–‡ä»¶åˆ°æ ‡å‡†ä½ç½®
        audio_dest = audio_dir / f"sample_{i+1:03d}.wav"
        shutil.copy2(audio_src, audio_dest)
        
        # å¤„ç†è½¬å½•æ–‡ä»¶
        transcript_text = ""
        transcript_src = transcripts.get(audio_stem)
        
        if transcript_src and Path(transcript_src).exists():
            try:
                with open(transcript_src, 'r', encoding='utf-8') as f:
                    transcript_text = f.read().strip()
                    
                # ä¿å­˜è½¬å½•æ–‡ä»¶
                text_dest = text_dir / f"sample_{i+1:03d}.txt"
                with open(text_dest, 'w', encoding='utf-8') as f:
                    f.write(transcript_text)
                    
                logger.info(f"ğŸ“ è½¬å½•æ–‡æœ¬: {transcript_text[:50]}...")
                
            except Exception as e:
                logger.warning(f"âš ï¸ è¯»å–è½¬å½•å¤±è´¥ {transcript_src}: {e}")
                
                # åˆ›å»ºç©ºè½¬å½•æ–‡ä»¶
                text_dest = text_dir / f"sample_{i+1:03d}.txt"
                with open(text_dest, 'w', encoding='utf-8') as f:
                    f.write("# è½¬å½•æ–‡ä»¶è¯»å–å¤±è´¥")
        else:
            # åˆ›å»ºå ä½ç¬¦è½¬å½•æ–‡ä»¶
            text_dest = text_dir / f"sample_{i+1:03d}.txt"
            with open(text_dest, 'w', encoding='utf-8') as f:
                f.write(f"# è€å¹´äººè¯­éŸ³æ ·æœ¬ {i+1}")
            transcript_text = f"è€å¹´äººè¯­éŸ³æ ·æœ¬ {i+1}"
        
        # è®°å½•æ•°æ®é¡¹
        dataset_item = {
            'id': f"sample_{i+1:03d}",
            'audio_file': str(audio_dest.relative_to(output_path)),
            'text_file': str(text_dest.relative_to(output_path)),
            'transcript': transcript_text,
            'original_audio_path': audio_info['original_path'],
            'size_mb': audio_info['size_mb']
        }
        
        dataset_items.append(dataset_item)
        logger.info(f"âœ… å¤„ç†å®Œæˆ: {dataset_item['id']}")
    
    # åˆ›å»ºæ•°æ®é›†å…ƒæ•°æ®
    metadata = {
        'dataset_name': 'SeniorTalk Sample Dataset',
        'source': 'BAAI/SeniorTalk',
        'description': 'ä»SeniorTalkæ•°æ®é›†æå–çš„è€å¹´äººè¯­éŸ³æ ·æœ¬',
        'total_samples': len(dataset_items),
        'structure': {
            'audio/': 'éŸ³é¢‘æ–‡ä»¶ (.wav)',
            'text/': 'è½¬å½•æ–‡ä»¶ (.txt)',
            'metadata/': 'å…ƒæ•°æ®æ–‡ä»¶'
        },
        'samples': dataset_items
    }
    
    # ä¿å­˜å…ƒæ•°æ®
    metadata_file = metadata_dir / "dataset_info.json"
    with open(metadata_file, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    
    # åˆ›å»ºç®€å•çš„ç´¢å¼•æ–‡ä»¶
    index_file = output_path / "index.txt"
    with open(index_file, 'w', encoding='utf-8') as f:
        f.write("# SeniorTalk Sample Dataset Index\n")
        f.write("# Format: audio_file|text_file|transcript\n\n")
        
        for item in dataset_items:
            f.write(f"{item['audio_file']}|{item['text_file']}|{item['transcript']}\n")
    
    logger.info(f"ğŸ“‹ æ•°æ®é›†åˆ›å»ºå®Œæˆ: {output_path}")
    logger.info(f"ğŸ“Š åŒ…å« {len(dataset_items)} ä¸ªæ ·æœ¬")
    logger.info(f"ğŸ“‹ å…ƒæ•°æ®æ–‡ä»¶: {metadata_file}")
    logger.info(f"ğŸ“„ ç´¢å¼•æ–‡ä»¶: {index_file}")
    
    return metadata

def main():
    """ä¸»å‡½æ•°"""
    
    print("ğŸš€ SeniorTalkæ•°æ®è§£å‹ä¸æ•´ç†å·¥å…·")
    print("=" * 60)
    
    # æŸ¥æ‰¾taræ–‡ä»¶
    tar_file = "data/raw/audio/seniortalk_asr_single/sentence_data/wav/train/train-0001.tar"
    
    if not Path(tar_file).exists():
        logger.error(f"âŒ æœªæ‰¾åˆ°taræ–‡ä»¶: {tar_file}")
        return
    
    # è®¾ç½®è·¯å¾„
    extract_base_dir = "data/processed/seniortalk_extracted"
    final_dataset_dir = "data/processed/seniortalk_samples"
    
    logger.info(f"ğŸ“¦ æ‰¾åˆ°taræ–‡ä»¶: {tar_file}")
    logger.info(f"ğŸ“ è§£å‹åˆ°: {extract_base_dir}")
    logger.info(f"ğŸ¯ æœ€ç»ˆæ•°æ®é›†: {final_dataset_dir}")
    
    # ç¬¬1æ­¥: è§£å‹taræ–‡ä»¶ï¼ˆé™åˆ¶æ•°é‡ï¼‰
    extracted_files = extract_tar_with_limit(
        tar_path=tar_file,
        extract_dir=extract_base_dir,
        max_files=5  # åªè§£å‹5ä¸ªæ–‡ä»¶ç”¨äºæµ‹è¯•
    )
    
    if not extracted_files:
        logger.error("âŒ æ²¡æœ‰æˆåŠŸè§£å‹ä»»ä½•æ–‡ä»¶")
        return
    
    # ç¬¬2æ­¥: æŸ¥æ‰¾è½¬å½•æ–‡ä»¶
    transcripts = find_corresponding_transcripts(
        audio_files=extracted_files,
        base_dir=Path(tar_file).parent.parent.parent.parent  # sentence_dataç›®å½•
    )
    
    # ç¬¬3æ­¥: åˆ›å»ºæ ‡å‡†æ•°æ®é›†ç»“æ„
    metadata = create_dataset_structure(
        extracted_files=extracted_files,
        transcripts=transcripts,
        output_dir=final_dataset_dir
    )
    
    # æ˜¾ç¤ºç»“æœ
    print(f"\nğŸ‰ æ•°æ®æ•´ç†å®Œæˆ!")
    print(f"ğŸ“ æ•°æ®é›†ä½ç½®: {final_dataset_dir}")
    print(f"ğŸ“Š æ ·æœ¬æ•°é‡: {metadata['total_samples']}")
    
    print(f"\nğŸ“‚ ç›®å½•ç»“æ„:")
    print(f"  {final_dataset_dir}/")
    print(f"  â”œâ”€â”€ audio/          # éŸ³é¢‘æ–‡ä»¶")
    print(f"  â”œâ”€â”€ text/           # è½¬å½•æ–‡ä»¶")
    print(f"  â”œâ”€â”€ metadata/       # å…ƒæ•°æ®")
    print(f"  â””â”€â”€ index.txt       # ç´¢å¼•æ–‡ä»¶")
    
    print(f"\nğŸ’¡ æ¥ä¸‹æ¥:")
    print(f"  1. æ£€æŸ¥æ•°æ®: ls -la {final_dataset_dir}/audio/")
    print(f"  2. ä¿®æ”¹ test_enhanced_asr.py ä½¿ç”¨æ–°æ•°æ®")
    print(f"  3. è¿è¡Œæµ‹è¯•: python scripts/test_enhanced_asr.py")

if __name__ == "__main__":
    main() 