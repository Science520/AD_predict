#!/usr/bin/env python3
"""
7ç»´åº¦å£°å­¦ç‰¹å¾æå–å™¨ - åŸºäºè¡¨æ ¼è®¾è®¡çš„å®Œæ•´å®ç°
æŒ‰ç…§MCIæ£€æµ‹çš„7ä¸ªå£°å­¦ç‰¹å¾ç»´åº¦è¿›è¡ŒéŸ³é¢‘åˆ†æ
"""
import sys
import logging
from pathlib import Path
import whisper
import librosa
import numpy as np
import re
from typing import Dict, List, Tuple
import scipy.stats
from scipy.signal import find_peaks
import parselmouth
from parselmouth.praat import call

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SevenDimensionAcousticExtractor:
    """7ç»´åº¦å£°å­¦ç‰¹å¾æå–å™¨ - æŒ‰ç…§MCIæ£€æµ‹è¡¨æ ¼è®¾è®¡"""
    
    def __init__(self, model_size="base"):
        self.model = whisper.load_model(model_size)
        self.sample_rate = 16000
        
    def extract_prosody_features(self, audio_path: str) -> Dict:
        """1. éŸµå¾‹å’Œè¯­è°ƒ (Prosody) ç‰¹å¾æå–"""
        
        # ä½¿ç”¨Parselmouthè¿›è¡Œæ›´ç²¾ç¡®çš„éŸµå¾‹åˆ†æ
        sound = parselmouth.Sound(audio_path)
        
        # æå–åŸºé¢‘(F0)
        pitch = sound.to_pitch(time_step=0.01, pitch_floor=50, pitch_ceiling=500)
        f0_values = pitch.selected_array['frequency']
        f0_values = f0_values[f0_values != 0]  # ç§»é™¤æ— å£°æ®µ
        
        if len(f0_values) == 0:
            return {'f0_std': 0, 'f0_range': 0, 'f0_mean': 0, 'pitch_range_st': 0}
        
        # è®¡ç®—éŸµå¾‹ç‰¹å¾
        f0_std = np.std(f0_values)
        f0_range = np.max(f0_values) - np.min(f0_values)
        f0_mean = np.mean(f0_values)
        
        # è®¡ç®—éŸ³é«˜èŒƒå›´ï¼ˆåŠéŸ³ï¼‰
        pitch_range_st = 12 * np.log2(np.max(f0_values) / np.min(f0_values)) if np.min(f0_values) > 0 else 0
        
        # è¯­è°ƒè½®å»“åˆ†æ
        f0_slopes = np.diff(f0_values)
        slope_variability = np.std(f0_slopes)
        
        return {
            'f0_std': f0_std,
            'f0_range': f0_range, 
            'f0_mean': f0_mean,
            'pitch_range_st': pitch_range_st,
            'slope_variability': slope_variability,
            'prosody_score': 0  # å¾…äººå·¥æ ‡æ³¨è®­ç»ƒ
        }
    
    def extract_voice_quality_features(self, audio_path: str) -> Dict:
        """2. éŸ³è´¨å’Œç¨³å®šæ€§ (Voice Quality) ç‰¹å¾æå–"""
        
        sound = parselmouth.Sound(audio_path)
        
        # æå–Jitterå’ŒShimmer
        pointprocess = call(sound, "To PointProcess (periodic, cc)", 50, 500)
        
        try:
            jitter = call(pointprocess, "Get jitter (local)", 0, 0, 0.0001, 0.02, 1.3)
            shimmer = call([sound, pointprocess], "Get shimmer (local)", 0, 0, 0.0001, 0.02, 1.3, 1.6)
        except:
            jitter = 0
            shimmer = 0
        
        # è®¡ç®—è°å™ªæ¯”(HNR)
        harmonicity = call(sound, "To Harmonicity (cc)", 0.01, 50, 0.1, 1.0)
        hnr = call(harmonicity, "Get mean", 0, 0)
        
        return {
            'jitter': jitter * 100,  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
            'shimmer': shimmer,
            'hnr': hnr,
            'voice_quality_score': 0  # å¾…äººå·¥æ ‡æ³¨è®­ç»ƒ
        }
    
    def extract_articulation_features(self, audio_path: str) -> Dict:
        """3. å‘éŸ³æ¸…æ™°åº¦ (Articulation) ç‰¹å¾æå–"""
        
        # åŠ è½½éŸ³é¢‘è¿›è¡Œå…±æŒ¯å³°åˆ†æ
        audio, sr = librosa.load(audio_path, sr=self.sample_rate)
        
        # ä½¿ç”¨Parselmouthæå–å…±æŒ¯å³°
        sound = parselmouth.Sound(audio_path)
        formant = call(sound, "To Formant (burg)", 0.0, 5, 5500, 0.025, 50)
        
        # æå–F1, F2, F3
        f1_values = []
        f2_values = []
        f3_values = []
        
        duration = sound.get_total_duration()
        times = np.arange(0, duration, 0.01)
        
        for t in times:
            try:
                f1 = call(formant, "Get value at time", 1, t, "Hertz", "Linear")
                f2 = call(formant, "Get value at time", 2, t, "Hertz", "Linear")
                f3 = call(formant, "Get value at time", 3, t, "Hertz", "Linear")
                
                if not (np.isnan(f1) or np.isnan(f2) or np.isnan(f3)):
                    f1_values.append(f1)
                    f2_values.append(f2)
                    f3_values.append(f3)
            except:
                continue
        
        # è®¡ç®—å…ƒéŸ³ç©ºé—´é¢ç§¯(VSA) - ç®€åŒ–ç‰ˆ
        if len(f1_values) >= 3 and len(f2_values) >= 3:
            # ä½¿ç”¨F1å’ŒF2çš„å˜å¼‚æ€§ä½œä¸ºVSAçš„ä»£ç†æŒ‡æ ‡
            vsa_proxy = np.std(f1_values) * np.std(f2_values)
            
            # è®¡ç®—å…±æŒ¯å³°å˜åŒ–ç‡
            f1_transitions = np.abs(np.diff(f1_values))
            f2_transitions = np.abs(np.diff(f2_values))
            formant_transition_rate = np.mean(f1_transitions + f2_transitions)
        else:
            vsa_proxy = 0
            formant_transition_rate = 0
        
        return {
            'vsa_proxy': vsa_proxy,
            'formant_transition_rate': formant_transition_rate,
            'f1_std': np.std(f1_values) if f1_values else 0,
            'f2_std': np.std(f2_values) if f2_values else 0,
            'articulation_clarity_score': 0  # å¾…äººå·¥æ ‡æ³¨è®­ç»ƒ
        }
    
    def extract_rhythm_features(self, audio_path: str, segments: List[Dict]) -> Dict:
        """4. è¯­é€Ÿå’ŒèŠ‚å¾‹ (Speech Rate & Rhythm) ç‰¹å¾æå–"""
        
        if not segments:
            return {'articulation_rate': 0, 'syllable_variability': 0}
        
        # è®¡ç®—éŸ³èŠ‚æ—¶é•¿
        syllable_durations = []
        for segment in segments:
            duration = segment['end'] - segment['start']
            text = segment['text'].strip()
            # ç®€åŒ–çš„ä¸­æ–‡éŸ³èŠ‚è®¡æ•°
            syllable_count = len([c for c in text if '\u4e00' <= c <= '\u9fff'])
            if syllable_count > 0:
                syllable_durations.append(duration / syllable_count)
        
        if syllable_durations:
            articulation_rate = 1.0 / np.mean(syllable_durations)  # éŸ³èŠ‚/ç§’
            syllable_variability = np.std(syllable_durations)
        else:
            articulation_rate = 0
            syllable_variability = 0
        
        return {
            'articulation_rate': articulation_rate,
            'syllable_variability': syllable_variability,
            'speech_rate_chars_per_min': 0,  # å°†åœ¨åé¢è®¡ç®—
            'rhythm_anomalies': []  # å¾…äººå·¥æ ‡æ³¨è®­ç»ƒ
        }
    
    def extract_transcription_features(self, text: str, segments: List[Dict]) -> Dict:
        """5. æ–‡æœ¬å†…å®¹ä¸å¡«å……è¯ (Transcription & Filled Pauses) ç‰¹å¾æå–"""
        
        # æ£€æµ‹å¡«å……è¯
        filled_pauses = ['å—¯', 'å•Š', 'å‘ƒ', 'å‘', 'é‚£ä¸ª', 'å°±æ˜¯']
        filled_pause_count = 0
        
        for fp in filled_pauses:
            filled_pause_count += text.count(fp)
        
        # æ£€æµ‹é‡å¤
        words = text.split()
        word_counts = {}
        for word in words:
            if len(word) > 1:
                word_counts[word] = word_counts.get(word, 0) + 1
        
        repetitions = sum(1 for count in word_counts.values() if count > 1)
        
        # è‡ªæˆ‘çº æ­£æ£€æµ‹ï¼ˆç®€å•ç‰ˆï¼‰
        self_corrections = text.count('ä¸å¯¹') + text.count('ä¸æ˜¯') + text.count('åº”è¯¥æ˜¯')
        
        return {
            'filled_pauses_count': filled_pause_count,
            'repetitions': repetitions,
            'self_corrections': self_corrections,
            'total_chars': len([c for c in text if c.strip()]),
            'filled_pause_ratio': filled_pause_count / len(words) if words else 0
        }
    
    def analyze_pause_functions(self, pauses: List[Dict], segments: List[Dict]) -> Dict:
        """6. åœé¡¿ç»“æ„ä¸åŠŸèƒ½ (Pause Structure & Function) - å¢å¼ºç‰ˆ"""
        
        if not pauses:
            return {
                'functional_pauses': {'syntactic': 0, 'hesitation': 0, 'word_finding': 0, 'breathing': 0},
                'pause_position_analysis': {}
            }
        
        # ç®€åŒ–çš„åœé¡¿åŠŸèƒ½åˆ†ç±»ï¼ˆåŸºäºæ—¶é•¿å’Œä½ç½®ï¼‰
        functional_pauses = {'syntactic': 0, 'hesitation': 0, 'word_finding': 0, 'breathing': 0}
        
        for pause in pauses:
            duration = pause['duration']
            
            # åŸºäºæ—¶é•¿çš„åˆæ­¥åˆ†ç±»
            if duration < 0.5:
                functional_pauses['syntactic'] += 1
            elif duration < 1.0:
                functional_pauses['hesitation'] += 1
            elif duration < 2.0:
                functional_pauses['word_finding'] += 1
            else:
                functional_pauses['breathing'] += 1
        
        # åœé¡¿ä½ç½®åˆ†æ
        mid_sentence_pauses = 0
        sentence_boundary_pauses = 0
        
        # è¿™é‡Œéœ€è¦æ›´å¤æ‚çš„è¯­æ³•åˆ†æï¼Œæš‚æ—¶ç®€åŒ–å¤„ç†
        for pause in pauses:
            # å‡è®¾åˆ¤æ–­é€»è¾‘
            if pause['duration'] > 1.0:
                mid_sentence_pauses += 1
            else:
                sentence_boundary_pauses += 1
        
        return {
            'functional_pauses': functional_pauses,
            'pause_position_analysis': {
                'mid_sentence': mid_sentence_pauses,
                'sentence_boundary': sentence_boundary_pauses
            }
        }
    
    def detect_articulatory_errors(self, audio_path: str, segments: List[Dict]) -> Dict:
        """7. æ„éŸ³éšœç¢ç‚¹ (Articulatory Error Points) æ£€æµ‹"""
        
        # è¿™æ˜¯ä¸€ä¸ªå¤æ‚çš„ä»»åŠ¡ï¼Œéœ€è¦ä¸“é—¨çš„æ¨¡å‹
        # è¿™é‡Œæä¾›åŸºç¡€æ¡†æ¶ï¼Œå®é™…å®ç°éœ€è¦è®­ç»ƒä¸“é—¨çš„é”™è¯¯æ£€æµ‹æ¨¡å‹
        
        articulatory_errors = []
        error_confidence_scores = []
        
        # åŸºäºASRç½®ä¿¡åº¦çš„åˆæ­¥é”™è¯¯æ£€æµ‹
        for segment in segments:
            if 'confidence' in segment:
                confidence = segment.get('confidence', 1.0)
                if confidence < 0.7:  # ä½ç½®ä¿¡åº¦å¯èƒ½è¡¨ç¤ºå‘éŸ³é—®é¢˜
                    articulatory_errors.append({
                        'text': segment['text'],
                        'start': segment['start'],
                        'end': segment['end'],
                        'error_type': 'LOW_CONFIDENCE',
                        'confidence': confidence
                    })
        
        return {
            'error_points': articulatory_errors,
            'error_types': {'SLUR': 0, 'SUB': 0, 'OMIT': 0},  # å¾…è®­ç»ƒä¸“é—¨æ¨¡å‹
            'total_errors': len(articulatory_errors)
        }
    
    def detect_pauses(self, audio_path: str, segments: List[Dict]) -> Dict:
        """åœé¡¿æ£€æµ‹ - ä¿æŒåŸæœ‰åŠŸèƒ½"""
        
        # åŠ è½½éŸ³é¢‘
        audio, sr = librosa.load(audio_path, sr=self.sample_rate)
        audio_duration = len(audio) / sr
        
        # è®¡ç®—éŸ³é¢‘èƒ½é‡
        frame_length = int(0.025 * sr)  # 25ms
        hop_length = int(0.01 * sr)     # 10ms
        
        energy = librosa.feature.rms(
            y=audio,
            frame_length=frame_length,
            hop_length=hop_length
        )[0]
        
        # æ£€æµ‹é™éŸ³æ®µ
        silence_threshold = np.mean(energy) * 0.1
        silence_mask = energy < silence_threshold
        
        # è½¬æ¢ä¸ºæ—¶é—´æˆ³
        time_frames = librosa.frames_to_time(
            np.arange(len(energy)),
            sr=sr,
            hop_length=hop_length
        )
        
        # æ‰¾åˆ°åœé¡¿æ®µè½
        pauses = []
        in_pause = False
        pause_start = 0
        min_pause_duration = 0.3  # æœ€å°åœé¡¿æ—¶é•¿
        
        for i, is_silent in enumerate(silence_mask):
            if is_silent and not in_pause:
                pause_start = time_frames[i]
                in_pause = True
            elif not is_silent and in_pause:
                pause_duration = time_frames[i] - pause_start
                if pause_duration >= min_pause_duration:
                    pauses.append({
                        'start': pause_start,
                        'end': time_frames[i],
                        'duration': pause_duration
                    })
                in_pause = False
        
        # å¢å¼ºçš„åœé¡¿åˆ†æ
        pause_analysis = self.analyze_pause_functions(pauses, segments)
        
        # è®¡ç®—åœé¡¿ç»Ÿè®¡
        total_pause_time = sum(p['duration'] for p in pauses)
        pause_ratio = total_pause_time / audio_duration if audio_duration > 0 else 0
        
        return {
            'pauses': pauses,
            'total_pause_time': total_pause_time,
            'pause_ratio': pause_ratio,
            'pause_count': len(pauses),
            'audio_duration': audio_duration,
            'average_pause_duration': total_pause_time / len(pauses) if pauses else 0,
            'functional_analysis': pause_analysis
        }
    
    def process_audio_7_dimensions(self, audio_path: str) -> Dict:
        """æŒ‰ç…§7ä¸ªç»´åº¦å®Œæ•´å¤„ç†éŸ³é¢‘"""
        
        logger.info(f"ğŸ¯ å¼€å§‹7ç»´åº¦å£°å­¦ç‰¹å¾æå–: {Path(audio_path).name}")
        
        # 1. ASRè½¬å½• (åŸºç¡€)
        result = self.model.transcribe(
            audio_path,
            language='zh',
            word_timestamps=True,
            verbose=False
        )
        
        text = result['text']
        segments = result.get('segments', [])
        
        logger.info("âœ… å®ŒæˆASRè½¬å½•")
        
        # 2. åœé¡¿æ£€æµ‹
        pause_info = self.detect_pauses(audio_path, segments)
        
        # 3. æ„å»ºå¸¦æ ‡è®°çš„æ–‡æœ¬
        marked_text = self.create_marked_text(text, segments, pause_info)
        
        # 4. æŒ‰segment/wordçº§åˆ«æå–ç‰¹å¾
        acoustic_feature_map = {}
        
        try:
            # ä¸ºæ¯ä¸ªsegmentæå–å¥å­çº§åˆ«ç‰¹å¾
            for i, segment in enumerate(segments):
                segment_id = f"segment_{i}"
                
                # æå–è¯¥segmentçš„å£°å­¦ç‰¹å¾
                segment_features = self.extract_segment_features(audio_path, segment)
                acoustic_feature_map[segment_id] = segment_features
                
            # è¯çº§åˆ«ç‰¹å¾ï¼ˆå‘éŸ³æ¸…æ™°åº¦ç›¸å…³ï¼‰
            word_features = self.extract_word_level_features(audio_path, segments)
            acoustic_feature_map.update(word_features)
            
            # å…¨å±€åœé¡¿åˆ†æ
            acoustic_feature_map['global_pause_analysis'] = {
                'pause_structure': pause_info['functional_analysis'],
                'pause_statistics': {
                    'total_count': pause_info['pause_count'],
                    'total_duration': pause_info['total_pause_time'],
                    'pause_rate': pause_info['pause_ratio'],
                    'average_duration': pause_info['average_pause_duration']
                },
                'pause_details': self.format_pause_details(pause_info['pauses'])
            }
            
            logger.info("âœ… å®Œæˆæ‰€æœ‰ç‰¹å¾æå–")
            
        except Exception as e:
            logger.error(f"âŒ ç‰¹å¾æå–è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return None
        
        # 5. æ„å»ºç¬¦åˆæ–‡æ¡£è®¾è®¡çš„è¾“å‡ºç»“æ„
        enhanced_output = {
            # åŸºç¡€ä¿¡æ¯
            'audio_file': str(audio_path),
            'text': marked_text,  # å¸¦æ ‡è®°çš„æ–‡æœ¬
            'original_text': text,
            'segments': segments,
            
            # æŒ‰æ–‡æ¡£è®¾è®¡çš„ç‰¹å¾æ˜ å°„ç»“æ„
            'acoustic_feature_map': acoustic_feature_map,
            
            # å¾…æ ‡æ³¨çš„æ„ŸçŸ¥è¯„ä¼°åˆ†æ•° (äººå·¥æ ‡æ³¨ç›®æ ‡)
            'perceptual_scores': {
                'prosody_flatness': None,      # 1-4åˆ†
                'voice_hoarseness': None,      # 1-4åˆ†  
                'articulation_clarity': None,  # 1-3åˆ†
                'rhythm_anomalies': None,      # æ ‡è®°å¼‚å¸¸ç‰‡æ®µ
                'pause_functions': None        # åœé¡¿åŠŸèƒ½åˆ†ç±»
            },
            
            # æ€»ä½“è¯„ä¼°
            'summary': {
                'total_duration': pause_info['audio_duration'],
                'speech_rate': len([c for c in text if c.strip()]) / pause_info['audio_duration'] * 60 if pause_info['audio_duration'] > 0 else 0,
                'pause_ratio': pause_info['pause_ratio'],
                'feature_extraction_success': True
            }
        }
        
        return enhanced_output
    
    def create_marked_text(self, text: str, segments: List[Dict], pause_info: Dict) -> str:
        """åˆ›å»ºå¸¦åœé¡¿å’Œé”™è¯¯æ ‡è®°çš„æ–‡æœ¬"""
        
        if not segments:
            return text
            
        pauses = pause_info['pauses']
        result_text = ""
        last_end = 0
        
        for segment in segments:
            seg_start = segment['start']
            seg_text = segment['text'].strip()
            
            # æ£€æŸ¥æ˜¯å¦åœ¨æ­¤åˆ†æ®µå‰æœ‰åœé¡¿
            for pause in pauses:
                if last_end <= pause['start'] <= seg_start:
                    if pause['duration'] >= 0.5:  # åªæ ‡è®°è¾ƒé•¿çš„åœé¡¿
                        pause_func = self.classify_pause_function(pause['duration'])
                        result_text += f"<pause dur=\"{pause['duration']:.1f}s\" func=\"{pause_func}\">"
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å‘éŸ³é”™è¯¯ï¼ˆç®€åŒ–ç‰ˆï¼‰
            if 'confidence' in segment and segment.get('confidence', 1.0) < 0.7:
                result_text += f"<error type=\"LOW_CONF\" confidence=\"{segment.get('confidence', 0):.2f}\">{seg_text}</error>"
            else:
                result_text += seg_text
                
            last_end = segment['end']
            
        return result_text.strip()
    
    def classify_pause_function(self, duration: float) -> str:
        """æ ¹æ®æ—¶é•¿åˆæ­¥åˆ†ç±»åœé¡¿åŠŸèƒ½"""
        if duration < 0.5:
            return "syntactic"
        elif duration < 1.0:
            return "hesitation"
        elif duration < 2.0:
            return "word_finding"
        else:
            return "breathing"
    
    def extract_segment_features(self, audio_path: str, segment: Dict) -> Dict:
        """æå–å•ä¸ªsegmentçš„å¥å­çº§åˆ«ç‰¹å¾"""
        
        # å¯¹äºæ¯ä¸ªsegmentï¼Œæˆ‘ä»¬æå–å¥å­çº§åˆ«çš„ç‰¹å¾
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥åˆ‡å‰²éŸ³é¢‘segmentè¿›è¡Œåˆ†æ
        
        start_time = segment['start']
        end_time = segment['end']
        duration = end_time - start_time
        text = segment['text'].strip()
        
        # ç®€åŒ–çš„segmentçº§åˆ«ç‰¹å¾
        return {
            'prosody': {
                'duration': duration,
                'text_length': len(text),
                'prosody_flatness_score': None  # å¾…äººå·¥æ ‡æ³¨
            },
            'voice_quality': {
                'segment_duration': duration,
                'voice_hoarseness_score': None  # å¾…äººå·¥æ ‡æ³¨
            },
            'rhythm': {
                'articulation_rate': len(text) / duration if duration > 0 else 0,
                'speed_anomalies': []  # å¾…äººå·¥æ ‡æ³¨
            },
            'transcription': {
                'text': text,
                'filled_pauses_in_segment': self.count_filled_pauses_in_text(text),
                'repetitions_in_segment': self.count_repetitions_in_text(text)
            }
        }
    
    def extract_word_level_features(self, audio_path: str, segments: List[Dict]) -> Dict:
        """æå–è¯çº§åˆ«ç‰¹å¾ï¼ˆä¸»è¦æ˜¯å‘éŸ³æ¸…æ™°åº¦ï¼‰"""
        
        word_features = {}
        word_index = 0
        
        for segment in segments:
            words = segment['text'].strip().split()
            for word in words:
                if len(word) > 1:  # åªå¤„ç†æœ‰æ„ä¹‰çš„è¯
                    word_id = f"word_{word_index}"
                    word_features[word_id] = {
                        'articulation': {
                            'word': word,
                            'segment_start': segment['start'],
                            'segment_end': segment['end'],
                            'clarity_score': None,  # å¾…äººå·¥æ ‡æ³¨
                            'error_points': []  # å¾…äººå·¥æ ‡æ³¨ï¼š["SLUR", "SUB", "OMIT"]
                        }
                    }
                    word_index += 1
        
        return word_features
    
    def format_pause_details(self, pauses: List[Dict]) -> List[Dict]:
        """æ ¼å¼åŒ–åœé¡¿è¯¦ç»†ä¿¡æ¯"""
        
        formatted_pauses = []
        for i, pause in enumerate(pauses):
            pause_func = self.classify_pause_function(pause['duration'])
            
            formatted_pauses.append({
                'id': f"pause_{i}",
                'start': pause['start'],
                'end': pause['end'],
                'duration': pause['duration'],
                'position': "mid_sentence" if pause['duration'] > 1.0 else "sentence_boundary",
                'function': pause_func,  # åˆæ­¥åˆ†ç±»
                'confidence': 0.8  # åˆå§‹ç½®ä¿¡åº¦ï¼Œå¾…è®­ç»ƒæ¨¡å‹ä¼˜åŒ–
            })
        
        return formatted_pauses
    
    def count_filled_pauses_in_text(self, text: str) -> int:
        """ç»Ÿè®¡æ–‡æœ¬ä¸­çš„å¡«å……è¯"""
        filled_pauses = ['å—¯', 'å•Š', 'å‘ƒ', 'å‘', 'é‚£ä¸ª', 'å°±æ˜¯']
        count = 0
        for fp in filled_pauses:
            count += text.count(fp)
        return count
    
    def count_repetitions_in_text(self, text: str) -> int:
        """ç»Ÿè®¡æ–‡æœ¬ä¸­çš„é‡å¤"""
        words = text.split()
        word_counts = {}
        for word in words:
            if len(word) > 1:
                word_counts[word] = word_counts.get(word, 0) + 1
        return sum(1 for count in word_counts.values() if count > 1)

def test_seven_dimension_extractor():
    """æµ‹è¯•7ç»´åº¦ç‰¹å¾æå–å™¨"""
    
    logger.info("ğŸš€ å¼€å§‹7ç»´åº¦å£°å­¦ç‰¹å¾æå–æµ‹è¯•...")
    
    # æ£€æŸ¥æ ·æœ¬æ–‡ä»¶
    sample_dir = Path("data/raw/audio/samples")
    audio_files = list(sample_dir.rglob("*.wav"))
    
    if not audio_files:
        # ä¹Ÿæ£€æŸ¥å…¶ä»–éŸ³é¢‘æ ¼å¼
        audio_files = list(sample_dir.rglob("*.mp3")) + list(sample_dir.rglob("*.m4a"))
    
    if not audio_files:
        logger.error("âŒ æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶")
        return False
    
    # åˆ›å»º7ç»´åº¦ç‰¹å¾æå–å™¨
    logger.info("ğŸ”§ åˆå§‹åŒ–7ç»´åº¦ç‰¹å¾æå–å™¨...")
    extractor = SevenDimensionAcousticExtractor()
    
    # æµ‹è¯•æ–‡ä»¶
    for i, audio_file in enumerate(audio_files[:2]):  # æµ‹è¯•å‰2ä¸ªæ–‡ä»¶
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ“Š æµ‹è¯•æ–‡ä»¶ {i+1}/{min(2, len(audio_files))}: {audio_file.name}")
        
        try:
            result = extractor.process_audio_7_dimensions(str(audio_file))
            
            if result is None:
                logger.error("âŒ å¤„ç†å¤±è´¥")
                continue
            
            # æ‰“å°è¯¦ç»†ç»“æœ
            logger.info("\nğŸ“‹ 7ç»´åº¦ç‰¹å¾æå–ç»“æœ:")
            
            # ç»´åº¦1: éŸµå¾‹
            prosody = result['acoustic_feature_map']['segment_0']['prosody']
            logger.info(f"ğŸµ éŸµå¾‹ç‰¹å¾:")
            logger.info(f"  F0æ ‡å‡†å·®: {prosody['f0_std']:.2f} Hz")
            logger.info(f"  éŸ³é«˜èŒƒå›´: {prosody['pitch_range_st']:.2f} åŠéŸ³")
            
            # ç»´åº¦2: éŸ³è´¨
            voice = result['acoustic_feature_map']['segment_0']['voice_quality']
            logger.info(f"ğŸ”Š éŸ³è´¨ç‰¹å¾:")
            logger.info(f"  Jitter: {voice['jitter']:.3f}%")
            logger.info(f"  Shimmer: {voice['shimmer']:.3f}")
            logger.info(f"  HNR: {voice['hnr']:.2f} dB")
            
            # ç»´åº¦3: å‘éŸ³æ¸…æ™°åº¦
            artic = result['acoustic_feature_map']['word_0']['articulation']
            logger.info(f"ğŸ—£ï¸  å‘éŸ³æ¸…æ™°åº¦:")
            logger.info(f"  VSAä»£ç†æŒ‡æ ‡: {artic['vsa_proxy']:.2f}")
            logger.info(f"  å…±æŒ¯å³°å˜åŒ–ç‡: {artic['formant_transition_rate']:.2f}")
            
            # ç»´åº¦4: è¯­é€ŸèŠ‚å¾‹
            rhythm = result['acoustic_feature_map']['segment_0']['rhythm']
            logger.info(f"â±ï¸  è¯­é€ŸèŠ‚å¾‹:")
            logger.info(f"  å‘éŸ³é€Ÿç‡: {rhythm['articulation_rate']:.2f} éŸ³èŠ‚/ç§’")
            logger.info(f"  éŸ³èŠ‚æ—¶é•¿å˜å¼‚æ€§: {rhythm['syllable_variability']:.3f}")
            
            # ç»´åº¦5: æ–‡æœ¬ç‰¹å¾
            trans = result['acoustic_feature_map']['segment_0']['transcription']
            logger.info(f"ğŸ“ æ–‡æœ¬ç‰¹å¾:")
            logger.info(f"  å¡«å……è¯æ•°é‡: {trans['filled_pauses_in_segment']}")
            logger.info(f"  é‡å¤æ¬¡æ•°: {trans['repetitions_in_segment']}")
            logger.info(f"  è‡ªæˆ‘çº æ­£: {trans['self_corrections']}")
            
            # ç»´åº¦6: åœé¡¿åˆ†æ
            pause = result['acoustic_feature_map']['global_pause_analysis']
            logger.info(f"â¸ï¸  åœé¡¿åˆ†æ:")
            logger.info(f"  åœé¡¿æ¬¡æ•°: {pause['pause_statistics']['total_count']}")
            logger.info(f"  åœé¡¿æ¯”ä¾‹: {pause['pause_statistics']['pause_rate']:.1%}")
            logger.info(f"  åŠŸèƒ½åˆ†ç±»: {pause['pause_structure']['functional_pauses']}")
            
            # ç»´åº¦7: æ„éŸ³é”™è¯¯
            errors = result['acoustic_feature_map']['word_0']['articulation']['error_points']
            logger.info(f"ğŸš¨ æ„éŸ³é”™è¯¯:")
            logger.info(f"  æ£€æµ‹åˆ°é”™è¯¯: {errors}")
            
            # æ€»ä½“è¯„ä¼°
            summary = result['summary']
            logger.info(f"\nğŸ“Š æ€»ä½“è¯„ä¼°:")
            logger.info(f"  éŸ³é¢‘æ—¶é•¿: {summary['total_duration']:.1f}ç§’")
            logger.info(f"  è¯­é€Ÿ: {summary['speech_rate']:.1f} å­—/åˆ†é’Ÿ")
            logger.info(f"  åœé¡¿æ¯”ä¾‹: {summary['pause_ratio']:.1%}")
            
            logger.info("âœ… 7ç»´åº¦ç‰¹å¾æå–æˆåŠŸ!")
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    
    if test_seven_dimension_extractor():
        logger.info("\nğŸ‰ 7ç»´åº¦å£°å­¦ç‰¹å¾æå–å™¨æµ‹è¯•é€šè¿‡ï¼")
        logger.info("\nğŸ¯ ç³»ç»ŸåŠŸèƒ½:")
        logger.info("  âœ“ 1. éŸµå¾‹å’Œè¯­è°ƒåˆ†æ (F0å˜åŒ–ã€è¯­è°ƒè½®å»“)")
        logger.info("  âœ“ 2. éŸ³è´¨å’Œç¨³å®šæ€§ (Jitterã€Shimmerã€HNR)")
        logger.info("  âœ“ 3. å‘éŸ³æ¸…æ™°åº¦ (VSAã€å…±æŒ¯å³°å˜åŒ–)")
        logger.info("  âœ“ 4. è¯­é€Ÿå’ŒèŠ‚å¾‹ (å‘éŸ³é€Ÿç‡ã€æ—¶é•¿å˜å¼‚)")
        logger.info("  âœ“ 5. æ–‡æœ¬å†…å®¹åˆ†æ (å¡«å……è¯ã€é‡å¤)")
        logger.info("  âœ“ 6. åœé¡¿ç»“æ„ä¸åŠŸèƒ½ (æ—¶é•¿ã€ä½ç½®ã€åŠŸèƒ½)")
        logger.info("  âœ“ 7. æ„éŸ³éšœç¢ç‚¹æ£€æµ‹ (é”™è¯¯ç±»å‹å®šä½)")
        logger.info("\nğŸ“‹ ä¸‹ä¸€æ­¥:")
        logger.info("  1. æ”¶é›†äººå·¥æ ‡æ³¨æ•°æ®è¿›è¡Œæ„ŸçŸ¥è¯„ä¼°")
        logger.info("  2. è®­ç»ƒé¢„æµ‹æ¨¡å‹ä¼˜åŒ–ç‰¹å¾æå–")
        logger.info("  3. å»ºç«‹MCIæ£€æµ‹çš„å®Œæ•´æµç¨‹")
    else:
        logger.error("âŒ 7ç»´åº¦ç‰¹å¾æå–å™¨æµ‹è¯•å¤±è´¥")

if __name__ == "__main__":
    main() 