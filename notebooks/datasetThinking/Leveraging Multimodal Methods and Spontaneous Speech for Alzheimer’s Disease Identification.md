### 1
按类别均值的方法填补了缺失的 MMSE 分数,并用一个生成模型对其进行了优化。- 这里是优化分数，但这种做法符合我们后面过一次文本模型，对识别出的语句要重排序优化
### 2
使用 Whisper-large 模型自动将音频转录为文本

### 3
Koala 的降噪模型增强了语音并抑制了噪音
Koala: https://picovoice.ai/docs/api/koala-web/

### 4
Falcon 模型识别了主讲人并拼接了他们的语音片段，生成了一个“提取版”
Falcon: https://picovoice.ai/platform/falcon/

### 5 声学特征
1. Whisper 嵌入: Whisper-large 模型使用基于 Transformer 的编码器将输入音频信号编码为高维上下文特征向量，捕捉多样的特性。在本研究中，音频被切分为 30 秒的片段，并使用编码器从每个片段中提取特征。然后对片段级特征进行平均，以代表整个音频，用于后续分类。
2. 时序 Whisper 嵌入: 将音频切分为 30 秒的片段仅能捕捉全局特征，忽略了更精细的时间信息。为解决此问题，我们根据 16,000 Hz 的采样率将音频切分为 16 个更小的块。将每个块的 Whisper 嵌入拼接起来，创建一个具有时间序列感知的表示，称为时序 Whisper 嵌入，从而最小化填充（padding）的影响。
- 为什么这么做有用

### 6 语言学特征
1. 通用特征: 数据使用 Linguistic Feature Toolkit³（一个在计算语言学中常用的 Python 包）提取，计算了 129 个特征。这些特征用于衡量文本的词汇丰富度和句法复杂度。
LFTK 可在以下地址获取: https://github.com/brucewlee/lftk
2. 言语流畅性特征：根据不同任务设置
3. 停顿特征: 停顿特征包括使用基于能量的语音活动检测（VAD）算法提取的与时长相关的描述符。它包括 16 个用于描述停顿和言语间隔长度的描述符。
- 这个能量我考虑到了，算法再验证一下